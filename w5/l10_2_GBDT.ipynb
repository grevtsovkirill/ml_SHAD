{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Загрузите выборку из файла gbm-data.csv с помощью pandas и преобразуйте ее в массив numpy \n",
    "# (параметр values у датафрейма). В первой колонке файла с данными записано, была или нет реакция. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497009</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.273166</td>\n",
       "      <td>0.585445</td>\n",
       "      <td>0.743663</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.606291</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.803455</td>\n",
       "      <td>0.106105</td>\n",
       "      <td>0.411754</td>\n",
       "      <td>0.836582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
       "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
       "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
       "\n",
       "         D8        D9  ...    D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
       "0  0.585445  0.743663  ...        0      0      0      0      0      0      0   \n",
       "1  0.411754  0.836582  ...        1      1      1      1      0      1      0   \n",
       "\n",
       "   D1774  D1775  D1776  \n",
       "0      0      0      0  \n",
       "1      0      1      0  \n",
       "\n",
       "[2 rows x 1777 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_csv('gbm-data.csv')\n",
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.loc[:,'Activity'].values\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Все остальные колонки (d1 - d1776) содержат различные характеристики молекулы, такие как размер, форма и т.д. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.49700901, 0.1       , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.36666667, 0.60629148, 0.05      , ..., 0.        , 1.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.loc[:,'D1':'D1776'].values\n",
    "X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбейте выборку на обучающую и тестовую, используя функцию train_test_split с параметрами test_size = 0.8 \n",
    "#и random_state = 241.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.8, random_state=241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(y_pred):\n",
    "    return 1.0 / (1.0 + np.exp(-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(train_loss, test_loss, file_name):\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    # %matplotlib inline\n",
    "    plt.figure()\n",
    "    plt.plot(test_loss, 'r', linewidth=2)\n",
    "    plt.plot(train_loss, 'g', linewidth=2)\n",
    "    plt.legend(['test', 'train'])\n",
    "    plt.savefig(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.0190           11.28s\n",
      "         2           0.9192           11.25s\n",
      "         3           0.8272            9.86s\n",
      "         4           0.7834            9.00s\n",
      "         5           0.7109            8.75s\n",
      "         6           0.6368            8.99s\n",
      "         7           0.5797            8.88s\n",
      "         8           0.5610            8.45s\n",
      "         9           0.5185            8.25s\n",
      "        10           0.4984            7.97s\n",
      "        20           0.1999            7.61s\n",
      "        30           0.1313            6.96s\n",
      "        40           0.0790            6.75s\n",
      "        50           0.0511            6.36s\n",
      "        60           0.0352            5.99s\n",
      "        70           0.0245            5.58s\n",
      "        80           0.0162            5.23s\n",
      "        90           0.0114            4.88s\n",
      "       100           0.0077            4.57s\n",
      "       200           0.0004            1.37s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1255           10.74s\n",
      "         2           1.0035           10.75s\n",
      "         3           0.9386           10.77s\n",
      "         4           0.8844            9.91s\n",
      "         5           0.8381            9.54s\n",
      "         6           0.7995            9.22s\n",
      "         7           0.7559            8.90s\n",
      "         8           0.7205            8.78s\n",
      "         9           0.6958            8.75s\n",
      "        10           0.6725            8.77s\n",
      "        20           0.4672            8.20s\n",
      "        30           0.3179            7.84s\n",
      "        40           0.2274            7.50s\n",
      "        50           0.1774            7.02s\n",
      "        60           0.1394            6.65s\n",
      "        70           0.1050            6.26s\n",
      "        80           0.0805            5.85s\n",
      "        90           0.0650            5.44s\n",
      "       100           0.0511            5.07s\n",
      "       200           0.0058            1.61s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2095           10.82s\n",
      "         2           1.1006           10.61s\n",
      "         3           1.0240           10.51s\n",
      "         4           0.9729           10.42s\n",
      "         5           0.9387            9.82s\n",
      "         6           0.8948           10.10s\n",
      "         7           0.8621            9.71s\n",
      "         8           0.8360            9.30s\n",
      "         9           0.8171            8.96s\n",
      "        10           0.7883            8.76s\n",
      "        20           0.6164            7.60s\n",
      "        30           0.4933            7.05s\n",
      "        40           0.4248            6.66s\n",
      "        50           0.3345            6.49s\n",
      "        60           0.2760            6.13s\n",
      "        70           0.2263            5.79s\n",
      "        80           0.1971            5.40s\n",
      "        90           0.1693            5.03s\n",
      "       100           0.1388            4.75s\n",
      "       200           0.0294            1.59s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2613           10.45s\n",
      "         2           1.1715           10.70s\n",
      "         3           1.1009           10.61s\n",
      "         4           1.0529           10.54s\n",
      "         5           1.0130           10.57s\n",
      "         6           0.9740           10.53s\n",
      "         7           0.9475           10.43s\n",
      "         8           0.9197           11.04s\n",
      "         9           0.8979           10.68s\n",
      "        10           0.8730           10.73s\n",
      "        20           0.7207            8.76s\n",
      "        30           0.6055            7.91s\n",
      "        40           0.5244            7.22s\n",
      "        50           0.4501            6.77s\n",
      "        60           0.3908            6.32s\n",
      "        70           0.3372            5.95s\n",
      "        80           0.3009            5.57s\n",
      "        90           0.2603            5.27s\n",
      "       100           0.2327            4.99s\n",
      "       200           0.0835            1.60s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3199           11.94s\n",
      "         2           1.2645           12.04s\n",
      "         3           1.2170           11.57s\n",
      "         4           1.1775           11.36s\n",
      "         5           1.1404           11.36s\n",
      "         6           1.1106           11.21s\n",
      "         7           1.0844           11.08s\n",
      "         8           1.0617           10.95s\n",
      "         9           1.0411           10.86s\n",
      "        10           1.0223           10.81s\n",
      "        20           0.8864            9.68s\n",
      "        30           0.7844            8.49s\n",
      "        40           0.7176            7.66s\n",
      "        50           0.6590            7.09s\n",
      "        60           0.6120            6.57s\n",
      "        70           0.5599            6.17s\n",
      "        80           0.5242            5.73s\n",
      "        90           0.4829            5.34s\n",
      "       100           0.4473            4.96s\n",
      "       200           0.2379            1.60s\n"
     ]
    }
   ],
   "source": [
    "# 2. Обучите GradientBoostingClassifier с параметрами n_estimators=250, verbose=True, random_state=241 и \n",
    "# для каждого значения learning_rate из списка [1, 0.5, 0.3, 0.2, 0.1] проделайте следующее:\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "min_losses={}\n",
    "list = [1, 0.5, 0.3, 0.2, 0.1]\n",
    "#list = [1]\n",
    "for learning_rate in list:\n",
    "    clf = GradientBoostingClassifier(n_estimators=250, learning_rate=learning_rate, verbose=True, random_state=241)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Используйте метод staged_decision_function для предсказания качества на обучающей и \n",
    "    # тестовой выборке на каждой итерации.\n",
    "    train_pred_iters = clf.staged_decision_function(X_train) #staged_predict_proba\n",
    "    test_pred_iters = clf.staged_decision_function(X_test)\n",
    "    # Преобразуйте полученное предсказание с помощью сигмоидной функции по формуле \n",
    "    # 1 / (1 + e^{−y_pred}), # где y_pred — предсказанное значение.\n",
    "    \n",
    "    #Вычислите и постройте график значений log-loss (которую можно посчитать с помощью \n",
    "    # функции sklearn.metrics.log_loss) на обучающей и тестовой выборках,\n",
    "    train_loss = [ log_loss(y_train, sigmoid(pred)) for pred in train_pred_iters]\n",
    "    test_loss = [ log_loss(y_test, sigmoid(pred)) for pred in test_pred_iters]\n",
    "    best_iter = np.argmin(test_loss)\n",
    "    #а также найдите минимальное значение метрики и номер итерации,на которой оно достигается.\n",
    "    min_losses[learning_rate] = (test_loss[best_iter], best_iter)\n",
    "    plot(train_loss, test_loss, 'plots/%.1f.png' % (learning_rate))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.1: (0.5269201872275844, 51),\n",
       " 0.2: (0.531094637596885, 36),\n",
       " 0.3: (0.5423141110024554, 10),\n",
       " 0.5: (0.5582025523164261, 6),\n",
       " 1: (0.5822942594278476, 0)}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00, 0.58, 0\n",
      "0.50, 0.56, 6\n",
      "0.30, 0.54, 10\n",
      "0.20, 0.53, 36\n",
      "0.10, 0.53, 51\n"
     ]
    }
   ],
   "source": [
    "for i in list:\n",
    "    print (\"%.2f, %.2f, %d\" % (i, min_losses[i][0],min_losses[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Как можно охарактеризовать график качества на тестовой выборке, \n",
    "# начиная с некоторой итерации: переобучение (overfitting) или недообучение (underfitting)? \n",
    "# -> overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Приведите минимальное значение log-loss на тестовой выборке и номер итерации,\n",
    "# на котором оно достигается, при learning_rate = 0.2.\n",
    "#0.2: (0.531094637596885, 36),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 5. На этих же данных обучите RandomForestClassifier с количеством деревьев, \n",
    "# равным количеству итераций, на котором достигается наилучшее качество у градиентного \n",
    "# бустинга из предыдущего пункта, c random_state=241 и остальными параметрами по умолчанию. \n",
    "# Какое значение log-loss на тесте получается у этого случайного леса? \n",
    "# (Не забывайте, что предсказания нужно получать с помощью функции predict_proba. \n",
    "# В данном случае брать сигмоиду от оценки вероятности класса не нужно)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=min_losses[0.2][1], random_state=241)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict_proba(X_test)[:, 1]\n",
    "rf_score = log_loss(y_test, rf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54\n"
     ]
    }
   ],
   "source": [
    "print (\"%.2f\" % rf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
